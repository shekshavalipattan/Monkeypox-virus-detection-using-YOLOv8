{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ui9cLjMdn17_"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6qiz-FfQkhFF"
      },
      "outputs": [],
      "source": [
        "!pip install tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip '/content/drive/MyDrive/Monkeypox_skin__image_dataset_modified.zip'"
      ],
      "metadata": {
        "id": "eMV0QxthcJon"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NTL9JAB_zn0k"
      },
      "outputs": [],
      "source": [
        "import tensorflow\n",
        "print(tensorflow.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sqs8xkUUT7ex"
      },
      "source": [
        "#Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k89Phl5nTfYU"
      },
      "outputs": [],
      "source": [
        "import cv2,os\n",
        "data_path='/content/Monkeypox_skin__image_dataset_modified'\n",
        "categories=os.listdir(data_path)\n",
        "labels=[i for i in range(len(categories))]\n",
        "\n",
        "label_dict=dict(zip(categories,labels)) #empty dictionary\n",
        "print(label_dict)\n",
        "print(categories)\n",
        "print(labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BScfeIRlTtlL"
      },
      "outputs": [],
      "source": [
        "img_size=256\n",
        "data=[]\n",
        "label=[]\n",
        "\n",
        "for category in categories:\n",
        "    folder_path=os.path.join(data_path,category)\n",
        "    img_names=os.listdir(folder_path)\n",
        "\n",
        "    for img_name in img_names:\n",
        "        img_path=os.path.join(folder_path,img_name)\n",
        "        img=cv2.imread(img_path)\n",
        "        try:\n",
        "            gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "            resized=cv2.resize(gray,(img_size,img_size))\n",
        "            #resizing the image  into 256 x 256, since we need a fixed common size for all the images in the dataset\n",
        "            data.append(resized)\n",
        "            label.append(label_dict[category])\n",
        "            #appending the image and the label(categorized) into the list (dataset)\n",
        "        except Exception as e:\n",
        "            print('Exception:',e)\n",
        "            #if any exception rasied, the exception will be printed here. And pass to the next image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mYQHryCXVQa9"
      },
      "source": [
        "# Rescale and assign  categorical labels"
      ]
    },
    {
      "source": [
        "import numpy as np\n",
        "data=np.array(data)/255.0\n",
        "data=np.reshape(data,(data.shape[0],img_size,img_size,1))\n",
        "label=np.array(label)\n",
        "from tensorflow.keras.utils import to_categorical # Use to_categorical directly from tensorflow.keras.utils\n",
        "new_label=to_categorical(label)"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "3XHNxfr6ARcE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M2Ww7WuoeRAo",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "new_label.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "at-tkV9EUH8v"
      },
      "source": [
        "#CNN Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w5yQijqzVHJN",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L1JcfG4MdVZ2",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "data.shape[1:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XgsZogOtUPm2"
      },
      "outputs": [],
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense,Activation,Flatten,Dropout\n",
        "from keras.layers import Conv2D,MaxPooling2D\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "\n",
        "model1=Sequential()\n",
        "\n",
        "model1.add(Conv2D(128,(3,3),input_shape=data.shape[1:]))\n",
        "model1.add(Activation('relu'))\n",
        "model1.add(MaxPooling2D(pool_size=(2,2)))\n",
        "#The first CNN layer followed by Relu and MaxPooling layers\n",
        "\n",
        "model1.add(Conv2D(64,(3,3)))\n",
        "model1.add(Activation('relu'))\n",
        "model1.add(MaxPooling2D(pool_size=(2,2)))\n",
        "#The second convolution layer followed by Relu and MaxPooling layers\n",
        "\n",
        "model1.add(Conv2D(32,(3,3)))\n",
        "model1.add(Activation('relu'))\n",
        "model1.add(MaxPooling2D(pool_size=(2,2)))\n",
        "#The thrid convolution layer followed by Relu and MaxPooling layers\n",
        "\n",
        "model1.add(Flatten())\n",
        "#Flatten layer to stack the output convolutions from 3rd convolution layer\n",
        "model1.add(Dropout(0.2))\n",
        "\n",
        "model1.add(Dense(128,activation='relu'))\n",
        "#Dense layer of 128 neurons\n",
        "\n",
        "model1.add(Dropout(0.1))\n",
        "model1.add(Dense(64,activation='relu'))\n",
        "#Dense layer of 64 neurons\n",
        "\n",
        "model1.add(Dense(4,activation='softmax'))\n",
        "#The Final layer with two outputs for two categories\n",
        "\n",
        "model1.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yfCMzZEpcyAM",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "model1.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lzs7FPsncqKT"
      },
      "source": [
        "# Splitting data into traning and testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XQRqq87MZfSk"
      },
      "outputs": [],
      "source": [
        "### Install the Split - folder package\n",
        "!pip install split-folders[full]\n",
        "#### Import the package\n",
        "import splitfolders\n",
        "###### Path of input folder\n",
        "input_folder = '/content/Monkeypox_skin__image_dataset_modified'\n",
        "#######ration of split is 70%, 20% and 10%\n",
        "splitfolders.ratio(input_folder, output=\"dataset_train\",\n",
        "                   seed=42, ratio=(.8, .2 ),\n",
        "                   group_prefix=None)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1oHT4H09UT8-"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_train,x_test,y_train,y_test=train_test_split(data,new_label,test_size=0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j3BCXcrumxpv"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.figure(figsize=(10,10))\n",
        "for i in range(20):\n",
        "    plt.subplot(5,5,i+1)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.grid(False)\n",
        "    plt.imshow(np.squeeze(x_test[i]))\n",
        "    plt.xlabel(categories[np.argmax(y_test[i])])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rmpEGWUMUUnh"
      },
      "outputs": [],
      "source": [
        "history=model1.fit(x_train,y_train,epochs=100,validation_split=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GWIlgOnjzdhT"
      },
      "outputs": [],
      "source": [
        "model1.save('model.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dTE4J3IGUWlt"
      },
      "outputs": [],
      "source": [
        "from matplotlib import pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H1TU9-z2UZlj"
      },
      "outputs": [],
      "source": [
        "# plot the training loss and accuracy\n",
        "N = 100 #number of epochs\n",
        "plt.style.use(\"ggplot\")\n",
        "plt.figure()\n",
        "plt.plot(np.arange(0, N), history.history[\"loss\"], label=\"train_loss\")\n",
        "plt.plot(np.arange(0, N), history.history[\"val_loss\"], label=\"val_loss\")\n",
        "plt.plot(np.arange(0, N), history.history[\"accuracy\"], label=\"train_acc\")\n",
        "plt.plot(np.arange(0, N), history.history[\"val_accuracy\"], label=\"val_acc\")\n",
        "plt.title(\"Training Loss and Accuracy\")\n",
        "plt.xlabel(\"Epoch #\")\n",
        "plt.ylabel(\"Loss/Accuracy\")\n",
        "plt.legend(loc=\"center right\")\n",
        "plt.savefig(\"CNN_Model\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qBKLBWTroYTu"
      },
      "outputs": [],
      "source": [
        "vaL_loss, val_accuracy= model1.evaluate(x_test, y_test, verbose=0)\n",
        "print(\"test loss:\", vaL_loss,'%')\n",
        "print(\"test accuracy:\", val_accuracy,\"%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mO_qh8EZl8qZ"
      },
      "outputs": [],
      "source": [
        "X = 5\n",
        "\n",
        "img_size = 256\n",
        "\n",
        "img_single = x_test[X]\n",
        "img_single = cv2.resize(img_single, (img_size, img_size))\n",
        "img_single = (np.expand_dims(img_single, 0))\n",
        "img_single = img_single.reshape(img_single.shape[0],256,256,1)\n",
        "\n",
        "predictions_single = model1.predict(img_single)\n",
        "print('A.I predicts:',categories[np.argmax(predictions_single)])\n",
        "print(\"Correct prediction for label\",np.argmax(y_test[X]),'is',categories[np.argmax(y_test[X])])\n",
        "plt.imshow(np.squeeze(img_single))\n",
        "plt.grid(False)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CD6GTkwhfbDF"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YO55PPeenshy"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "from mlxtend.plotting import plot_confusion_matrix\n",
        "\n",
        "test_labels = np.argmax(y_test, axis=1)\n",
        "predictions = model1.predict(x_test)\n",
        "predictions = np.argmax(predictions, axis=-1)\n",
        "\n",
        "\n",
        "cm  = confusion_matrix(test_labels, predictions)\n",
        "plt.figure()\n",
        "plot_confusion_matrix(cm,figsize=(12,8), hide_ticks=True,cmap=plt.cm.Blues)\n",
        "plt.xticks(range(4), ['Chickenpox','Measles','Monkeypox','Normal'], fontsize=16)\n",
        "plt.yticks(range(4), ['Chickenpox','Measles','Monkeypox','Normal'], fontsize=16)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XbcqNJdr2yPn"
      },
      "source": [
        "# **RESNET**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3qxdnuFy23CG"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras import backend as K\n",
        "import keras\n",
        "from keras.models import Sequential, Model,load_model\n",
        "from keras.optimizers import SGD\n",
        "from keras.callbacks import EarlyStopping,ModelCheckpoint\n",
        "from google.colab.patches import cv2_imshow\n",
        "from keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D, GlobalMaxPooling2D,MaxPool2D\n",
        "from keras.preprocessing import image\n",
        "from keras.initializers import glorot_uniform"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J61gZqxVb5om"
      },
      "outputs": [],
      "source": [
        "train_datagen = ImageDataGenerator(zoom_range=0.15,width_shift_range=0.2,height_shift_range=0.2,shear_range=0.15)\n",
        "test_datagen = ImageDataGenerator()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jJBPVEFZbgwr"
      },
      "outputs": [],
      "source": [
        "train_generator = train_datagen.flow_from_directory(\"/content/dataset_train/train\",target_size=(224, 224),batch_size=32,shuffle=True)\n",
        "test_generator = test_datagen.flow_from_directory(\"/content/dataset_train/val\",target_size=(224,224),batch_size=32,shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4RAXLCre3hJD"
      },
      "outputs": [],
      "source": [
        "def identity_block(X, f, filters, stage, block):\n",
        "\n",
        "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
        "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
        "    F1, F2, F3 = filters\n",
        "\n",
        "    X_shortcut = X\n",
        "\n",
        "    X = Conv2D(filters=F1, kernel_size=(1, 1), strides=(1, 1), padding='valid', name=conv_name_base + '2a', kernel_initializer=glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis=3, name=bn_name_base + '2a')(X)\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "    X = Conv2D(filters=F2, kernel_size=(f, f), strides=(1, 1), padding='same', name=conv_name_base + '2b', kernel_initializer=glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis=3, name=bn_name_base + '2b')(X)\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "    X = Conv2D(filters=F3, kernel_size=(1, 1), strides=(1, 1), padding='valid', name=conv_name_base + '2c', kernel_initializer=glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis=3, name=bn_name_base + '2c')(X)\n",
        "\n",
        "    X = Add()([X, X_shortcut])# SKIP Connection\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "    return X"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8WMG7N0q3n3P"
      },
      "outputs": [],
      "source": [
        "def convolutional_block(X, f, filters, stage, block, s=2):\n",
        "\n",
        "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
        "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
        "\n",
        "    F1, F2, F3 = filters\n",
        "\n",
        "    X_shortcut = X\n",
        "\n",
        "    X = Conv2D(filters=F1, kernel_size=(1, 1), strides=(s, s), padding='valid', name=conv_name_base + '2a', kernel_initializer=glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis=3, name=bn_name_base + '2a')(X)\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "    X = Conv2D(filters=F2, kernel_size=(f, f), strides=(1, 1), padding='same', name=conv_name_base + '2b', kernel_initializer=glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis=3, name=bn_name_base + '2b')(X)\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "    X = Conv2D(filters=F3, kernel_size=(1, 1), strides=(1, 1), padding='valid', name=conv_name_base + '2c', kernel_initializer=glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis=3, name=bn_name_base + '2c')(X)\n",
        "\n",
        "    X_shortcut = Conv2D(filters=F3, kernel_size=(1, 1), strides=(s, s), padding='valid', name=conv_name_base + '1', kernel_initializer=glorot_uniform(seed=0))(X_shortcut)\n",
        "    X_shortcut = BatchNormalization(axis=3, name=bn_name_base + '1')(X_shortcut)\n",
        "\n",
        "    X = Add()([X, X_shortcut])\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "    return X"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TLhltCla21RD"
      },
      "outputs": [],
      "source": [
        "def ResNet50(input_shape=(224, 224, 3)):\n",
        "\n",
        "    X_input = Input(input_shape)\n",
        "\n",
        "    X = ZeroPadding2D((3, 3))(X_input)\n",
        "\n",
        "    X = Conv2D(64, (7, 7), strides=(2, 2), name='conv1', kernel_initializer=glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis=3, name='bn_conv1')(X)\n",
        "    X = Activation('relu')(X)\n",
        "    X = MaxPooling2D((3, 3), strides=(2, 2))(X)\n",
        "\n",
        "    X = convolutional_block(X, f=3, filters=[64, 64, 256], stage=2, block='a', s=1)\n",
        "    X = identity_block(X, 3, [64, 64, 256], stage=2, block='b')\n",
        "    X = identity_block(X, 3, [64, 64, 256], stage=2, block='c')\n",
        "\n",
        "\n",
        "    X = convolutional_block(X, f=3, filters=[128, 128, 512], stage=3, block='a', s=2)\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=3, block='b')\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=3, block='c')\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=3, block='d')\n",
        "\n",
        "    X = convolutional_block(X, f=3, filters=[256, 256, 1024], stage=4, block='a', s=2)\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='b')\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='c')\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='d')\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='e')\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='f')\n",
        "\n",
        "    X = X = convolutional_block(X, f=3, filters=[512, 512, 2048], stage=5, block='a', s=2)\n",
        "    X = identity_block(X, 3, [512, 512, 2048], stage=5, block='b')\n",
        "    X = identity_block(X, 3, [512, 512, 2048], stage=5, block='c')\n",
        "\n",
        "    X = AveragePooling2D(pool_size=(2, 2), padding='same')(X)\n",
        "\n",
        "    model = Model(inputs=X_input, outputs=X, name='ResNet50')\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xUqDcT0i9jeF"
      },
      "outputs": [],
      "source": [
        "base_model = ResNet50(input_shape=(224, 224, 3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dYhhizkh9pOB"
      },
      "outputs": [],
      "source": [
        "headModel = base_model.output\n",
        "headModel = Flatten()(headModel)\n",
        "headModel=Dense(256, activation='relu', name='fc1',kernel_initializer=glorot_uniform(seed=0))(headModel)\n",
        "headModel=Dense(128, activation='relu', name='fc2',kernel_initializer=glorot_uniform(seed=0))(headModel)\n",
        "headModel = Dense( 1,activation='sigmoid', name='fc3',kernel_initializer=glorot_uniform(seed=0))(headModel)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yirfNawk9q9D"
      },
      "outputs": [],
      "source": [
        "model = Model(inputs=base_model.input, outputs=headModel)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r2u1s8Dk9wU3"
      },
      "outputs": [],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ogMdKzYq-AWQ"
      },
      "outputs": [],
      "source": [
        "es=EarlyStopping(monitor='val_accuracy', mode='max', verbose=1, patience=20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1YmMAi13-iMo"
      },
      "outputs": [],
      "source": [
        "mc = ModelCheckpoint('/content/gdrive/My Drive/best_model.h5', monitor='val_accuracy', mode='max')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BOMQEoaMcru5"
      },
      "outputs": [],
      "source": [
        "opt = SGD(lr=1e-3, momentum=0.9)\n",
        "model.compile(loss=\"binary_crossentropy\", optimizer=opt,metrics=[\"accuracy\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cx04fFL3dRSp"
      },
      "outputs": [],
      "source": [
        "H = model.fit_generator(train_generator,validation_data=test_generator,epochs=100,verbose=1,callbacks=[mc,es])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xnd4-q2AbkNX"
      },
      "outputs": [],
      "source": [
        "from matplotlib import pyplot as plt\n",
        "N = 100 #number of epochs\n",
        "plt.style.use(\"ggplot\")\n",
        "plt.figure()\n",
        "plt.plot(np.arange(0, N), history.history[\"loss\"], label=\"train_loss\")\n",
        "plt.plot(np.arange(0, N), history.history[\"val_loss\"], label=\"val_loss\")\n",
        "plt.plot(np.arange(0, N), history.history[\"accuracy\"], label=\"train_acc\")\n",
        "plt.plot(np.arange(0, N), history.history[\"val_accuracy\"], label=\"val_acc\")\n",
        "plt.title(\"Training Loss and Accuracy\")\n",
        "plt.xlabel(\"Epoch #\")\n",
        "plt.ylabel(\"Loss/Accuracy\")\n",
        "plt.legend(loc=\"center right\")\n",
        "plt.savefig(\"RESNET50\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NPh-IfoMbrTC"
      },
      "outputs": [],
      "source": [
        "X = 4\n",
        "\n",
        "img_size = 256\n",
        "\n",
        "img_single = x_test[X]\n",
        "img_single = cv2.resize(img_single, (img_size, img_size))\n",
        "img_single = (np.expand_dims(img_single, 0))\n",
        "img_single = img_single.reshape(img_single.shape[0],256,256,1)\n",
        "\n",
        "predictions_single = model1.predict(img_single)\n",
        "print('A.I predicts:',categories[np.argmax(predictions_single)])\n",
        "print(\"Correct prediction for label\",np.argmax(y_test[X]),'is',categories[np.argmax(y_test[X])])\n",
        "plt.imshow(np.squeeze(img_single))\n",
        "plt.grid(False)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zcggh6zRbzii"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "from mlxtend.plotting import plot_confusion_matrix\n",
        "\n",
        "test_labels = np.argmax(y_test, axis=1)\n",
        "predictions = model1.predict(x_test)\n",
        "predictions = np.argmax(predictions, axis=-1)\n",
        "\n",
        "\n",
        "cm  = confusion_matrix(test_labels, predictions)\n",
        "plt.figure()\n",
        "plot_confusion_matrix(cm,figsize=(12,8), hide_ticks=True,cmap=plt.cm.Blues)\n",
        "plt.xticks(range(4), ['Chickenpox','Measles','Monkeypox','Normal'], fontsize=16)\n",
        "plt.yticks(range(4), ['Chickenpox','Measles','Monkeypox','Normal'], fontsize=16)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5H8f4823fdrE"
      },
      "source": [
        "# **VGG 16**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "drKb2TMCosGV"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.layers import Dense,Flatten,Conv2D,Activation,Dropout\n",
        "from keras import backend as K\n",
        "import keras\n",
        "from keras.models import Sequential, Model\n",
        "from keras.models import load_model\n",
        "from keras.optimizers import SGD\n",
        "from keras.callbacks import EarlyStopping,ModelCheckpoint\n",
        "from keras.layers import MaxPool2D\n",
        "from google.colab.patches import cv2_imshow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-A2CHrHln486"
      },
      "outputs": [],
      "source": [
        "train_datagen = ImageDataGenerator(zoom_range=0.15,width_shift_range=0.2,height_shift_range=0.2,shear_range=0.15)\n",
        "test_datagen = ImageDataGenerator()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qC0sUAYKocXU"
      },
      "outputs": [],
      "source": [
        "train_generator = train_datagen.flow_from_directory(\"/content/dataset_train/train\",target_size=(224, 224),batch_size=32,shuffle=True)\n",
        "test_generator = test_datagen.flow_from_directory(\"/content/dataset_train/test\",target_size=(224,224),batch_size=32,shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qrw2uaAMoca1"
      },
      "outputs": [],
      "source": [
        "def VGG16():\n",
        "    model2 = Sequential()\n",
        "    model2.add(Conv2D(input_shape=(224,224,3),filters=64,kernel_size=(3,3),padding=\"same\", activation=\"relu\"))\n",
        "    model2.add(Conv2D(filters=64,kernel_size=(3,3),padding=\"same\", activation=\"relu\"))\n",
        "    model2.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
        "    model2.add(Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "    model2.add(Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "    model2.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
        "    model2.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "    model2.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "    model2.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "    model2.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
        "    model2.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "    model2.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "    model2.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "    model2.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
        "    model2.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "    model2.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "    model2.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "    model2.add(MaxPool2D(pool_size=(2,2),strides=(2,2),name='vgg16'))\n",
        "    model2.add(Flatten(name='flatten'))\n",
        "    model2.add(Dense(256, activation='relu', name='fc1'))\n",
        "    model2.add(Dense(128, activation='relu', name='fc2'))\n",
        "    model2.add(Dense(1, activation='sigmoid', name='output'))\n",
        "    return model2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nbmqs-snocdZ"
      },
      "outputs": [],
      "source": [
        "model2=VGG16()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fBDHafKiocgt"
      },
      "outputs": [],
      "source": [
        "model2.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g9b9tyU-ocjD"
      },
      "outputs": [],
      "source": [
        "Vgg16 = Model(inputs=model2.input, outputs=model2.get_layer('vgg16').output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VPaYvdCWn5B1"
      },
      "outputs": [],
      "source": [
        "opt = SGD(lr=1e-4, momentum=0.9)\n",
        "model2.compile(loss=\"binary_crossentropy\", optimizer=opt,metrics=[\"accuracy\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0za8_izJn5Ey"
      },
      "outputs": [],
      "source": [
        "es=EarlyStopping(monitor='val_accuracy', mode='max', verbose=1, patience=20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pZvGCQ5Xn5Ih"
      },
      "outputs": [],
      "source": [
        "mc = ModelCheckpoint('/content/gdrive/My Drive/vgg_model.h5', monitor='val_accuracy', mode='max', save_best_only=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ee9ErcD9n5Kw"
      },
      "outputs": [],
      "source": [
        "V=model2.fit_generator(train_generator,validation_data=test_generator,epochs=100,verbose=1,callbacks=[mc,es])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib import pyplot as plt\n",
        "N = 100 #number of epochs\n",
        "plt.style.use(\"ggplot\")\n",
        "plt.figure()\n",
        "plt.plot(np.arange(0, N), history.history[\"loss\"], label=\"train_loss\")\n",
        "plt.plot(np.arange(0, N), history.history[\"val_loss\"], label=\"val_loss\")\n",
        "plt.plot(np.arange(0, N), history.history[\"accuracy\"], label=\"train_acc\")\n",
        "plt.plot(np.arange(0, N), history.history[\"val_accuracy\"], label=\"val_acc\")\n",
        "plt.title(\"Training Loss and Accuracy\")\n",
        "plt.xlabel(\"Epoch #\")\n",
        "plt.ylabel(\"Loss/Accuracy\")\n",
        "plt.legend(loc=\"center right\")\n",
        "plt.savefig(\"VGGNET\")"
      ],
      "metadata": {
        "id": "nWTx9rwDlBWm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = 64\n",
        "\n",
        "img_size = 256\n",
        "\n",
        "img_single = x_test[X]\n",
        "img_single = cv2.resize(img_single, (img_size, img_size))\n",
        "img_single = (np.expand_dims(img_single, 0))\n",
        "img_single = img_single.reshape(img_single.shape[0],256,256,1)\n",
        "\n",
        "predictions_single = model1.predict(img_single)\n",
        "print('A.I predicts:',categories[np.argmax(predictions_single)])\n",
        "print(\"Correct prediction for label\",np.argmax(y_test[X]),'is',categories[np.argmax(y_test[X])])\n",
        "plt.imshow(np.squeeze(img_single))\n",
        "plt.grid(False)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "_KiNPIeSlDM2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "from mlxtend.plotting import plot_confusion_matrix\n",
        "\n",
        "test_labels = np.argmax(y_test, axis=1)\n",
        "predictions = model1.predict(x_test)\n",
        "predictions = np.argmax(predictions, axis=-1)\n",
        "\n",
        "\n",
        "cm  = confusion_matrix(test_labels, predictions)\n",
        "plt.figure()\n",
        "plot_confusion_matrix(cm,figsize=(12,8), hide_ticks=True,cmap=plt.cm.Blues)\n",
        "plt.xticks(range(4), ['Chickenpox','Measles','Monkeypox','Normal'], fontsize=16)\n",
        "plt.yticks(range(4), ['Chickenpox','Measles','Monkeypox','Normal'], fontsize=16)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "UXLQQxuMlNTa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M33XFE-xn5O2"
      },
      "outputs": [],
      "source": [
        "model2.evaluate_generator(test_generator)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5kZvfjoy1Wbc"
      },
      "source": [
        "# **GOOGLE NET**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gx5iAzB-QAQk"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import *\n",
        "\n",
        "\n",
        "def inception_module(x, base_channels=32):\n",
        "  a = Conv2D(base_channels*2, 1, 1, activation='relu')(x)\n",
        "\n",
        "  b_1 = Conv2D(base_channels*4, 1, 1, activation='relu')(x)\n",
        "  b_2 = Conv2D(base_channels*4, 3, 1, padding='same', activation='relu')(b_1)\n",
        "\n",
        "  c_1 = Conv2D(base_channels, 1, 1, activation='relu')(x)\n",
        "  c_2 = Conv2D(base_channels, 5, 1, padding='same', activation='relu')(c_1)\n",
        "\n",
        "  d_1 = MaxPooling2D(3, 1, padding='same')(x)\n",
        "  d_2 = Conv2D(base_channels, 1, 1, activation='relu')(d_1)\n",
        "\n",
        "  return Concatenate(axis=-1)([a, b_2, c_2, d_2])\n",
        "\n",
        "inp = Input((224, 224, 3))\n",
        "\n",
        "maps = inception_module(inp)\n",
        "\n",
        "gap = GlobalAveragePooling2D()(maps)\n",
        "\n",
        "output = Dense(1, activation='sigmoid')(gap)\n",
        "\n",
        "model = Model(inputs=inp, outputs=output)\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EZ6W4eQwQY0S"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.losses import BinaryCrossentropy\n",
        "\n",
        "# Learning rate is also a hyperparameter\n",
        "model.compile(loss=BinaryCrossentropy(),\n",
        "              optimizer=Adam(learning_rate=0.001), metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KurR3xplQaCM"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "es = EarlyStopping(patience=20, monitor='loss')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D1zOVRQtQ7cM"
      },
      "outputs": [],
      "source": [
        "model.fit(\n",
        "    train_generator,\n",
        "    epochs=100,\n",
        "    validation_data=test_generator,\n",
        "    callbacks=[es]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = 120\n",
        "\n",
        "img_size = 256\n",
        "\n",
        "img_single = x_test[X]\n",
        "img_single = cv2.resize(img_single, (img_size, img_size))\n",
        "img_single = (np.expand_dims(img_single, 0))\n",
        "img_single = img_single.reshape(img_single.shape[0],256,256,1)\n",
        "\n",
        "predictions_single = model1.predict(img_single)\n",
        "print('A.I predicts:',categories[np.argmax(predictions_single)])\n",
        "print(\"Correct prediction for label\",np.argmax(y_test[X]),'is',categories[np.argmax(y_test[X])])\n",
        "plt.imshow(np.squeeze(img_single))\n",
        "plt.grid(False)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "NVi--Z8hpMRA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "from mlxtend.plotting import plot_confusion_matrix\n",
        "\n",
        "test_labels = np.argmax(y_test, axis=1)\n",
        "predictions = model1.predict(x_test)\n",
        "predictions = np.argmax(predictions, axis=-1)\n",
        "\n",
        "\n",
        "cm  = confusion_matrix(test_labels, predictions)\n",
        "plt.figure()\n",
        "plot_confusion_matrix(cm,figsize=(12,8), hide_ticks=True,cmap=plt.cm.Blues)\n",
        "plt.xticks(range(4), ['Chickenpox','Measles','Monkeypox','Normal'], fontsize=16)\n",
        "plt.yticks(range(4), ['Chickenpox','Measles','Monkeypox','Normal'], fontsize=16)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ciYPPFvRpNDG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "VGG 19\n"
      ],
      "metadata": {
        "id": "malJDV-2pA3t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "from keras.applications import VGG19\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Flatten\n",
        "from keras.optimizers import SGD\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# ImageDataGenerator for data augmentation\n",
        "train_datagen = ImageDataGenerator(zoom_range=0.15, width_shift_range=0.2, height_shift_range=0.2, shear_range=0.15)\n",
        "test_datagen = ImageDataGenerator()\n",
        "\n",
        "# Data generators\n",
        "train_generator = train_datagen.flow_from_directory(\"/content/dataset_train/train\", target_size=(224, 224), batch_size=32, shuffle=True)\n",
        "test_generator = test_datagen.flow_from_directory(\"/content/dataset_train/test\", target_size=(224, 224), batch_size=32, shuffle=False)\n",
        "\n",
        "# Model definition\n",
        "def VGG19_custom(input_shape=(224, 224, 3), num_classes=4):\n",
        "    base_model = VGG19(weights='imagenet', include_top=False, input_shape=input_shape)\n",
        "\n",
        "    model = Sequential()\n",
        "    model.add(base_model)\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(256, activation='relu', name='fc1'))\n",
        "    model.add(Dense(128, activation='relu', name='fc2'))\n",
        "    model.add(Dense(num_classes, activation='softmax', name='output'))\n",
        "    return model\n",
        "\n",
        "model = VGG19_custom()\n",
        "\n",
        "# Model summary\n",
        "model.summary()\n",
        "\n",
        "# Model compilation\n",
        "opt = SGD(lr=1e-4, momentum=0.9)\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])\n",
        "\n",
        "# Early Stopping and Model Checkpoint callbacks\n",
        "es = EarlyStopping(monitor='val_accuracy', mode='max', verbose=1, patience=20)\n",
        "mc = ModelCheckpoint('/content/gdrive/My Drive/vgg_model.h5', monitor='val_accuracy', mode='max', save_best_only=True)\n",
        "\n",
        "# Model training\n",
        "history = model.fit_generator(train_generator, validation_data=test_generator, epochs=100, verbose=1, callbacks=[mc, es])\n",
        "\n",
        "# Plot training and validation curves\n",
        "plt.style.use(\"ggplot\")\n",
        "plt.figure()\n",
        "plt.plot(np.arange(0, len(history.history[\"loss\"])), history.history[\"loss\"], label=\"train_loss\")\n",
        "plt.plot(np.arange(0, len(history.history[\"val_loss\"])), history.history[\"val_loss\"], label=\"val_loss\")\n",
        "plt.plot(np.arange(0, len(history.history[\"accuracy\"])), history.history[\"accuracy\"], label=\"train_acc\")\n",
        "plt.plot(np.arange(0, len(history.history[\"val_accuracy\"])), history.history[\"val_accuracy\"], label=\"val_acc\")\n",
        "plt.title(\"Training Loss and Accuracy\")\n",
        "plt.xlabel(\"Epoch #\")\n",
        "plt.ylabel(\"Loss/Accuracy\")\n",
        "plt.legend(loc=\"center right\")\n",
        "plt.savefig(\"VGGNET\")\n",
        "\n",
        "# Rest of your code for displaying a single test image and confusion matrix...\n"
      ],
      "metadata": {
        "id": "Q1s875zIoqAk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = 80\n",
        "\n",
        "img_size = 256\n",
        "\n",
        "img_single = x_test[X]\n",
        "img_single = cv2.resize(img_single, (img_size, img_size))\n",
        "img_single = (np.expand_dims(img_single, 0))\n",
        "img_single = img_single.reshape(img_single.shape[0],256,256,1)\n",
        "\n",
        "predictions_single = model1.predict(img_single)\n",
        "print('A.I predicts:',categories[np.argmax(predictions_single)])\n",
        "print(\"Correct prediction for label\",np.argmax(y_test[X]),'is',categories[np.argmax(y_test[X])])\n",
        "plt.imshow(np.squeeze(img_single))\n",
        "plt.grid(False)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "YLHL58OvwM7G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "from mlxtend.plotting import plot_confusion_matrix\n",
        "\n",
        "test_labels = np.argmax(y_test, axis=1)\n",
        "predictions = model1.predict(x_test)\n",
        "predictions = np.argmax(predictions, axis=-1)\n",
        "\n",
        "\n",
        "cm  = confusion_matrix(test_labels, predictions)\n",
        "plt.figure()\n",
        "plot_confusion_matrix(cm,figsize=(12,8), hide_ticks=True,cmap=plt.cm.Blues)\n",
        "plt.xticks(range(4), ['Chickenpox','Measles','Monkeypox','Normal'], fontsize=16)\n",
        "plt.yticks(range(4), ['Chickenpox','Measles','Monkeypox','Normal'], fontsize=16)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "xGV5V79bwNCo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ultralytics"
      ],
      "metadata": {
        "id": "diUuRgH6xbTK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "YOLOv8"
      ],
      "metadata": {
        "id": "oRVVDKGK7j1j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### Install the Split - folder package\n",
        "!pip install split-folders[full]\n",
        "#### Import the package\n",
        "import splitfolders\n",
        "###### Path of input folder\n",
        "input_folder = '/content/Monkeypox_skin__image_dataset_modified'\n",
        "#######ration of split is 70%, 20% and 10%\n",
        "splitfolders.ratio(input_folder, output=\"dataset_train2\",\n",
        "                   seed=42, ratio=(.7, .2, .1),\n",
        "                   group_prefix=None)\n"
      ],
      "metadata": {
        "id": "4XJxMeT7Ddtx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "from ultralytics import YOLO\n",
        "model = YOLO(\"yolov8n-cls.pt\")\n",
        "\n",
        "results = model.train(data='/content/dataset_train2', epochs=50, imgsz=600)"
      ],
      "metadata": {
        "id": "fhpJKjeTxbZc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WfzJrTFdCPYY"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}